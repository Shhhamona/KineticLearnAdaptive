#!/usr/bin/env python3
"""
Analyze the k values generated by the active learning sampler to check:
1. If they fall within the expected uniform bounds [0.5*k_true, 2.0*k_true]
2. Distribution characteristics
3. Potential reasons for MSE degradation
"""

import numpy as np

# k_true values used as center
k_true = np.array([6.00e-16, 1.30e-15, 9.60e-16])

# Expected bounds from uniform sampling analysis: [0.5*k_true, 2.0*k_true]
expected_lower = k_true * 0.5
expected_upper = k_true * 2.0

print("Expected bounds (from uniform sampling analysis):")
for i, (lower, upper) in enumerate(zip(expected_lower, expected_upper)):
    print(f"  k[{i}]: [{lower:.3e}, {upper:.3e}]")

print(f"\nk_true: {k_true}")

# Your sampled k values from the run (50 parameter sets)
sampled_k_values = [
    [9.94188579e-16, 1.41543203e-15, 1.31251646e-15],
    [3.18676754e-16, 8.32247730e-16, 1.70966460e-15],
    [8.70283411e-16, 2.25115603e-15, 5.78060074e-16],
    [9.73923494e-16, 9.44746438e-16, 1.14892436e-15],
    [7.48656311e-16, 1.39902317e-15, 1.60600673e-15],
    [5.02316981e-16, 2.49130839e-15, 1.51478805e-15],
    [4.78256578e-16, 2.57586968e-15, 1.32387165e-15],
    [9.84477641e-16, 1.53979387e-15, 5.33415955e-16],
    [4.52199753e-16, 2.26093955e-15, 9.84945203e-16],
    [3.79505833e-16, 1.14017956e-15, 1.29099459e-15],
    [9.16823837e-16, 1.81487471e-15, 9.11611016e-16],
    [1.15805401e-15, 2.41052193e-15, 1.21776118e-15],
    [3.03553440e-16, 1.69238800e-15, 1.44979237e-15],
    [7.60973037e-16, 1.80089266e-15, 7.09238976e-16],
    [1.03135887e-15, 7.26599446e-16, 5.52687845e-16],
    [8.51273460e-16, 1.34650443e-15, 9.66454877e-16],
    [9.49579786e-16, 8.05245526e-16, 6.35611833e-16],
    [5.62688461e-16, 1.24564684e-15, 7.37620044e-16],
    [1.12599671e-15, 1.29490266e-15, 1.75559102e-15],
    [9.43118205e-16, 2.15896908e-15, 1.00612556e-15],
    [7.88289931e-16, 7.27920457e-16, 7.95027863e-16],
    [4.27953043e-16, 1.48750975e-15, 1.56359449e-15],
    [6.36006684e-16, 1.26410740e-15, 6.33906602e-16],
    [9.06720254e-16, 1.89115773e-15, 1.55222867e-15],
    [6.97649857e-16, 1.32537694e-15, 1.15649082e-15],
    [6.90612594e-16, 7.34039845e-16, 1.34148817e-15],
    [8.55990281e-16, 2.36583459e-15, 6.92573077e-16],
    [7.61824418e-16, 2.13831914e-15, 7.45010144e-16],
    [8.85357464e-16, 2.36228845e-15, 1.40890386e-15],
    [8.40935058e-16, 1.46414283e-15, 5.50024329e-16],
    [1.02470088e-15, 1.83087625e-15, 8.38002011e-16],
    [7.69482437e-16, 1.65125992e-15, 1.26106826e-15],
    [1.11778399e-15, 1.81578146e-15, 8.06553614e-16],
    [5.87312480e-16, 1.16132054e-15, 1.02923261e-15],
    [3.81413414e-16, 1.23669905e-15, 1.80801521e-15],
    [5.70630051e-16, 6.99529575e-16, 1.81251390e-15],
    [4.02585926e-16, 1.24097199e-15, 1.29611989e-15],
    [1.04581319e-15, 1.12204796e-15, 1.24819807e-15],
    [3.42206687e-16, 1.73727747e-15, 5.01398435e-16],
    [8.63658433e-16, 1.75273869e-15, 1.88817494e-15],
    [7.92827540e-16, 1.57650788e-15, 1.30516162e-15],
    [1.03735830e-15, 1.22095605e-15, 1.62013007e-15],
    [4.79052786e-16, 7.75289568e-16, 1.28864260e-15],
    [1.07116527e-15, 2.55869733e-15, 1.74336275e-15],
    [6.16487375e-16, 1.31243030e-15, 1.32124199e-15],
    [9.79182922e-16, 1.61534483e-15, 1.50074375e-15],
    [5.66365536e-16, 2.55530742e-15, 6.93888170e-16],
    [1.09554283e-15, 1.50950896e-15, 1.09696906e-15],
    [5.92960474e-16, 1.27063197e-15, 1.47920170e-15],
    [4.48514308e-16, 1.66360412e-15, 6.30652432e-16]
]

sampled_k = np.array(sampled_k_values)

print(f"\nAnalyzing {len(sampled_k)} sampled parameter sets:")

# Check bounds compliance
within_bounds = np.zeros(len(sampled_k), dtype=bool)
for i, k_sample in enumerate(sampled_k):
    within = np.all((k_sample >= expected_lower) & (k_sample <= expected_upper))
    within_bounds[i] = within
    if not within:
        violations = []
        for j in range(3):
            if k_sample[j] < expected_lower[j]:
                violations.append(f"k[{j}] too low: {k_sample[j]:.3e} < {expected_lower[j]:.3e}")
            if k_sample[j] > expected_upper[j]:
                violations.append(f"k[{j}] too high: {k_sample[j]:.3e} > {expected_upper[j]:.3e}")
        print(f"  PS {i}: OUT OF BOUNDS - {', '.join(violations)}")

print(f"\nBounds compliance: {np.sum(within_bounds)}/{len(sampled_k)} samples within expected bounds")
print(f"Compliance rate: {np.sum(within_bounds)/len(sampled_k)*100:.1f}%")

# Statistical analysis
print(f"\nStatistical analysis:")
for j in range(3):
    k_col = sampled_k[:, j]
    print(f"\nk[{j}] (true={k_true[j]:.3e}):")
    print(f"  Min:    {np.min(k_col):.3e} (ratio to true: {np.min(k_col)/k_true[j]:.2f})")
    print(f"  Max:    {np.max(k_col):.3e} (ratio to true: {np.max(k_col)/k_true[j]:.2f})")
    print(f"  Mean:   {np.mean(k_col):.3e} (ratio to true: {np.mean(k_col)/k_true[j]:.2f})")
    print(f"  Median: {np.median(k_col):.3e} (ratio to true: {np.median(k_col)/k_true[j]:.2f})")
    print(f"  Std:    {np.std(k_col):.3e}")
    
    # Expected range ratios
    expected_min_ratio = 0.5
    expected_max_ratio = 2.0
    actual_min_ratio = np.min(k_col) / k_true[j]
    actual_max_ratio = np.max(k_col) / k_true[j]
    
    print(f"  Expected range: [{expected_min_ratio:.1f}, {expected_max_ratio:.1f}] * k_true")
    print(f"  Actual range:   [{actual_min_ratio:.2f}, {actual_max_ratio:.2f}] * k_true")

# Check for potential MSE degradation causes
print(f"\n=== POTENTIAL CAUSES FOR MSE DEGRADATION ===")

# 1. Are we sampling outside the training distribution?
print(f"\n1. Sampling Range vs Training Distribution:")
print(f"   - If sampled k values go outside the training data range,")
print(f"     the model may struggle with extrapolation")
print(f"   - Training data was from uniform sampling: [0.5*k_true, 2.0*k_true]")
print(f"   - Current sampler uses same bounds, so this shouldn't be the issue")

# 2. Are we sampling too close to boundaries?
boundary_tolerance = 0.1  # 10% from boundaries
close_to_boundary = 0
for k_sample in sampled_k:
    for j in range(3):
        rel_pos = (k_sample[j] - expected_lower[j]) / (expected_upper[j] - expected_lower[j])
        if rel_pos < boundary_tolerance or rel_pos > (1 - boundary_tolerance):
            close_to_boundary += 1
            break

print(f"\n2. Boundary Effects:")
print(f"   - Samples close to boundaries (within {boundary_tolerance*100}%): {close_to_boundary}/{len(sampled_k)}")
print(f"   - Boundary rate: {close_to_boundary/len(sampled_k)*100:.1f}%")

# 3. Random sampling vs uncertainty-based sampling
print(f"\n3. Sampling Strategy:")
print(f"   - Current: Random sampling within bounds")
print(f"   - Issue: Random sampling may select points that don't improve the model")
print(f"   - Solution: Use uncertainty-based or acquisition function sampling")

# 4. Sample size per iteration
print(f"\n4. Sample Size per Iteration:")
print(f"   - Adding {len(sampled_k)} samples per iteration might be too many")
print(f"   - Large batches can include many uninformative samples")
print(f"   - Consider smaller batches (5-10 samples) for more targeted sampling")

# 5. Model capacity
print(f"\n5. Model Overfitting:")
print(f"   - SVR models might be overfitting to the specific training samples")
print(f"   - New samples might expose model limitations")
print(f"   - Consider: cross-validation, different kernels, or ensemble methods")

print(f"\n=== RECOMMENDATIONS ===")
print(f"1. Implement uncertainty-based sampling (model disagreement)")
print(f"2. Reduce samples per iteration to 5-10")
print(f"3. Add model validation during training")
print(f"4. Consider ensemble or different model architectures")
